---
title: "STATS 767 Project"
subtitle: "A Multivariate Approach to Modelling Lifestyle Risk Factors of Children Myopia in the US"
author: "Stephen Su"
date: "4 June 2021"
output:
  xaringan::moon_reader:
    nature:
      highlightLines: true
    css: xaringan-themer.css
---

```{r setup, echo = FALSE, cache = FALSE, results = 'hide'}
library(knitr)
options(
  htmltools.dir.version = FALSE, htmltools.preserve.raw = FALSE,
  tibble.width = 60, tibble.print_min = 6
)
opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, comment = "#>", fig.retina = 3,
  fig.align = "center", fig.show = "hold", cache.path = "cache/", cache = TRUE,
  dpi = 110, dev.args = list(png = list(type = "cairo"))
)
```

```{r xaringan-themer, include = FALSE, warning = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#035AA6",
  header_font_google = google_font("Josefin Sans"),
  text_font_google = google_font("Montserrat", "400", "400i"),
  code_font_google = google_font("Fira Mono")
)
```

```{r external, include = FALSE, cache = FALSE}
read_chunk("slide.R")
```

## Background

The association of lifestyle factors and myopia has been long discussed.

Since my childhood, I was repeated advised by optometrists that:

* My prescription could keep increasing until adulthood

* Spend more time outdoors, it will save your vision

* **Stay away from those electronic garbage (from Mom)**

* Take regular breaks and avoid prolonged focused reading

With Statistics, can we find supporting evidence for the claims above?

```{r start, echo = 2, error = TRUE}
```

Finding the answer is not easy, and the realm of medical-related statistics is full of variables with random behaviour (weak correlation, confounding, ...)

---

## The Data

The dataset is from [ggeop/Myopia-Study](https://github.com/ggeop/Myopia-Study).

* A subset of the research from Orinda Longitudinal Study of Myopia

* Conducted in 1989-1990 and 2000-2001

* Consists of 618 observations and 17 variables

However, we are only interested in seven of the variables.

```{r data, echo = 4}
```

---

## Variable Definition

```{r data-def, echo = FALSE}
```

---

## A First Glance

```{r expl, echo = FALSE, fig.height = 4}
```

* All numeric variables except for `age` are heavily right-skewed.

---

## Log-Transformation But ...

```{r minimum, highlight.output = c(2, 9)}
```

* A simple log-transformation is not feasible.

* A `log1p` transformation could be a good alternative.

---

## Seems to be Some Overshooting

```{r overfix, echo = FALSE, fig.height = 4}
```

* A `log1p` transformation seems to over-fix skewness of `sporthr` and `tvhr`.

---

## The Transformed Data

```{r data-trans, echo = FALSE, fig.height = 4}
```

* The transformed data is much better, despite departure from normality.

---

## Bivariate Association with Myopia

```{r effect, echo = FALSE, fig.height = 4}
```

* The bivariate correlations with myopia of the variables are relatively weak.

---

## More Diagnostics

.pull-left[
```{r eov}
```

* `sqrt` transformed variables have substantially larger variance.

* EOCV is compromised for better normality.
]

.pull-right[
```{r vif}
```

* The variance inflation factors are reasonably small.

* Concern of multicollinearity can be dismissed.
]

---

## Candidate Models

Principal Component Analysis (abbr. PCA)

* The first to consider upon approaching multivariate data

* A dimension reduction technique maximising total variability

* May not separate the myopic groups well

**Linear Discriminant Analysis (abbr. LDA)**

* Also a dimension reduction technique, maximises ANOVA F-statistic

* Could be affected by departure from EOCV and normality

**Quadratic Discriminant Analysis (abbr. QDA)**

* Relaxes the assumption of EOCV by modelling the whole Cov matrix

* Does not perform dimension reduction, cannot interpret loadings

PLS-Discriminant Analysis (abbr. PLS-DA)

* The data is far from rank deficiency, thus probably not needed

---

## Preliminary Models

A US study on children myopia suggests a prevalence of 24% (Theophanous et al., 2018) in the 2000s, including those without a need of correcting lenses.

* An *initial* prior of $(\pi_0, \pi_1) = (0.76, 0.24)$ is used.

```{r prelim, echo = -1}
```

.pull-left[
**Leave-One-Out Cross-Validation**

```{r loo-lda, echo = 2}
```
]

.pull-right[
<br>

```{r loo-qda}
```
]

---

## What is Wrong Here?

The classification of categories is based on the Bayes Discriminant Rule:

\begin{equation} f(\theta_i | \mathbf{x}) \propto f(\theta_i)f(\mathbf{x} | \theta_i) = \pi_if(\mathbf{x}) \end{equation}

```{r odds}
```

Under a null model (ignoring all the lifestyle variables), an individual is ~21 times more likely to be classified as non-myopic (posterior odds ratio).

* Remember: The bivariate correlation of *each* variable is weak.

Improving the sensitivity is achievable by increasing $\pi_1 = f(\theta_1)$.

**However, there exists no free lunch!!**

* $\mathbb{P}(\hat{X} = 1 | X = 1) \rightarrow 1$ as $\pi_1 \rightarrow 1$ and $\mathbb{P}(\hat{X} = 0 | X = 0) \rightarrow 1$ as $\pi_0 \rightarrow 1$

* $\mathbb{P}(\hat{X} = 1 | X = 0) \rightarrow 1$ as $\pi_1 \rightarrow 1$ and $\mathbb{P}(\hat{X} = 0 | X = 1) \rightarrow 1$ as $\pi_0 \rightarrow 1$

---

## The Sensitivity/Specificity Trade-Off

Blindly seeking sensitivity or specificity comes at a great price.

* Namely *Type I* and *Type II* errors

Instead, the goal is to minimise the *balanced error rate*.

* Equivalent to maximising the value of $sensitivity + specificity$

.pull-left[
**LDA**

```{r optim-lda, echo = FALSE}
```
]

.pull-right[
**QDA**

```{r optim-qda, echo = FALSE}
```
]

---

## The ROC Curve

.pull-left[
```{r roc-lda, echo = FALSE}
```
]

.pull-right[
```{r roc-qda, echo = FALSE}
```
]

The receiver operating characteristic curve evaluates the predictive power.

* QDA possesses slightly higher overall predictive power;

* Notwithstanding QDA has $sensitivity < 0.5$ (loses to a coin).

---

## The Decision

The two purposes of statistical models: **explanatory** and **predictive** modelling.

.pull-left[
**LDA**

* Selective interpretation of loadings makes it an ideal explanatory model.

* It possesses similar overall predictive power as QDA.

* Sensitivity is moderate.

* Specificity is moderate.
]

.pull-right[
**QDA**

* Interpretation of loadings is unfeasible, *cannot* serve as an explanatory model.

* It possesses similar overall predictive power as LDA.

* Sensitivity is *poor*.

* Specificity is good.
]

Contextually, both the explanatory and predictive capabilities are important.

.center[
**The Linear Discriminant Analysis model, with the prior of $(\pi_0, \pi_1) = (0.508, 0.492)$ (approximately uniform, uninformative),<br>is chosen to be the final model.**
]

---

## Model Interpretation

```{r score, echo = FALSE, fig.height = 1.7}
```

.pull-left[
```{r loadings, echo = FALSE}
```
]

.pull-right[
The risk of developing myopia:

* Increases mildly with age;

* Increases with the time spent in focused reading;

* Decreases with the time spent on sports or outdoor activities.

Surprisingly, the relationship between computer and television use time and myopia is unclear.
]

---

## LDA cf. Multiple Logistic Regression

Upon approaching a Bernoulli random variable of interest and some numeric covariates, you may recall logistic regression from **STATS 201/208/310/330**:

\begin{equation} \mathbf{Y}\overset{iid}{\sim}Bernoulli(\pmb{\theta})\;|\;logit(\pmb{\theta})=\mathbf{X}\pmb{\beta};\;\pmb{\theta}\in(0,1)^n,\;\pmb{\beta}\in\mathbb{R}^p,\;\mathbf{X}\in\mathbb{R}^n\times\mathbb{R}^p \end{equation}

The information-theoretic approach is adopted.
